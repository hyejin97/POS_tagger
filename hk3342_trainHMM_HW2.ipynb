{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load train files##\n",
    "####################\n",
    "train_file_1 = open(\"WSJ_02-21.pos\")\n",
    "train_file_2 = open(\"WSJ_24.pos\")\n",
    "train_list_1 = train_file_1.readlines()\n",
    "train_list_2 = train_file_2.readlines()\n",
    "train_list = train_list_1 + train_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preprocessing with OOV strategies##\n",
    "#####################################\n",
    "\n",
    "import string\n",
    "\n",
    "#Morphology\n",
    "unknown_words = [\"UNKNOWN_digit\", \"UNKNOWN_punct\", \"UNKNOWN_capital\", \"UNKNOWN_noun\", \"UNKNOWN_adj\", \"UNKNOWN_verb\", \"UNKNOWN_adv\", \"UNKNOWN\"]\n",
    "suffix_noun = [\"ment\", \"ness\", \"age\", \"ship\", \"ance\", \"cy\", \"ty\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"action\", \"ism\", \"ist\", \"ity\", \"ling\", \"or\", \"ry\", \"scape\"]\n",
    "suffix_adj = [\"ive\", \"ful\", \"ous\", \"able\", \"ible\", \"ly\", \"ese\", \"ian\", \"ic\", \"ish\", \"less\"]\n",
    "suffix_verb = [\"ize\", \"ify\", \"ise\", \"ate\"]\n",
    "suffix_adv = [\"wise\", \"ward\", \"wards\"]\n",
    "punctuations = set(string.punctuation)\n",
    "\n",
    "#Compute probability of UNKNOWN_WORD\n",
    "def tag_unknowns(word):\n",
    "    if any(word.endswith(suffix) for suffix in suffix_noun):\n",
    "        return \"UNKNOWN_noun\"\n",
    "    elif any(word.endswith(suffix) for suffix in suffix_adj):\n",
    "        return \"UNKNOWN_adj\"\n",
    "    elif any(word.endswith(suffix) for suffix in suffix_verb):\n",
    "        return \"UNKNOWN_verb\"\n",
    "    elif any(word.endswith(suffix) for suffix in suffix_adv):\n",
    "        return \"UNKNOWN_adv\"\n",
    "    elif any(char in punctuations for char in word):\n",
    "        return \"UNKNOWN_punct\"\n",
    "    elif any(char.isdigit() for char in word):\n",
    "        return \"UNKNOWN_digit\"\n",
    "    elif any(char.isupper() for char in word):\n",
    "        return \"UNKNOWN_capital\"\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "    \n",
    "    \n",
    "#treat words with freq < 2 as unknown\n",
    "tags = dict() \n",
    "vocabs = dict() \n",
    "for i in range(len(train_list)):\n",
    "    split_list = train_list[i].split()\n",
    "    if len(split_list) == 0:\n",
    "        continue\n",
    "        \n",
    "    word = split_list[0]\n",
    "    tag = split_list[1]\n",
    "    if word not in vocabs:\n",
    "        vocabs[word] = 1\n",
    "    else:\n",
    "        vocabs[word] += 1\n",
    "    if tag not in tags:\n",
    "        tags[tag] = 1\n",
    "    else:\n",
    "        tags[tag] += 1\n",
    "\n",
    "\n",
    "#Output : vocab_list, tags\n",
    "#vocab_list - vocabs list with unknown words\n",
    "vocab_list = []\n",
    "for vocab in vocabs.keys():\n",
    "    if vocabs[vocab] >= 2:\n",
    "        vocab_list.append(vocab)\n",
    "for unknown in unknown_words:\n",
    "    vocab_list.append(unknown)\n",
    "vocab_list.append(\"SOS\")\n",
    "vocab_list.append(\"EOS\")\n",
    "\n",
    "#tags - list of all possible states(all POS + begine/end of sentences)\n",
    "tags = list(tags.keys())\n",
    "tags.append(\"Begin_Sent\")\n",
    "tags.append(\"End_Sent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train transition and emission probabilities ##\n",
    "#################################################\n",
    "\n",
    "vocab_set = set(vocab_list)\n",
    "emission_dict = dict() #Calculating the possible tags for each word\n",
    "transition_dict = dict() #Calculating the probabilities of tag bigrams for transition probability  \n",
    "\n",
    "for i in range(len(train_list)):\n",
    "    split_list = train_list[i].split()\n",
    "    if len(split_list) == 0:\n",
    "        continue\n",
    "    \n",
    "    word = split_list[0]\n",
    "    tag = split_list[1]\n",
    "    \n",
    "    if word not in vocab_set: #handling unknown word\n",
    "        word = tag_unknowns(word)\n",
    "    \n",
    "    ##update emissions\n",
    "    if tag in emission_dict:\n",
    "        if word in emission_dict[tag]:\n",
    "            emission_dict[tag][word] += 1\n",
    "        else:\n",
    "            emission_dict[tag][word] = 1\n",
    "    else:\n",
    "        emission_dict[tag] = {word : 1}\n",
    "    \n",
    "    ##update transitions\n",
    "    #if begin of sentence\n",
    "    if i == 0:\n",
    "        transition_dict[\"Begin_Sent\"] = {tag : 1}\n",
    "        emission_dict[\"Begin_Sent\"] = {\"SOS\" : 1}\n",
    "        \n",
    "    #if end of sentence\n",
    "    elif i >= len(train_list) - 2:\n",
    "        if tag in transition_dict:\n",
    "            transition_dict[tag][\"End_Sent\"] = 1\n",
    "        else:\n",
    "            transition_dict[tag] = {\"End_Sent\" : 1}\n",
    "        emission_dict[\"End_Sent\"] = {\"EOS\" : 1}\n",
    "        \n",
    "    #else\n",
    "    else:\n",
    "        if train_list[i+1] == '\\n':\n",
    "            next_split_list = train_list[i+2].split()\n",
    "            next_tag = next_split_list[1]\n",
    "        else:\n",
    "            next_split_list = train_list[i+1].split()\n",
    "            next_tag = next_split_list[1]\n",
    "\n",
    "        if tag in transition_dict:\n",
    "            if next_tag in transition_dict[tag]:\n",
    "                transition_dict[tag][next_tag] += 1\n",
    "            else:\n",
    "                transition_dict[tag][next_tag] = 1\n",
    "        else:\n",
    "            transition_dict[tag] = {next_tag : 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "##convert to probabilities##\n",
    "############################\n",
    "pseudocount = 0.001 #smoothing parameter\n",
    "\n",
    "for tag in tags:\n",
    "    count_tot = 0\n",
    "    for word in emission_dict[tag]:\n",
    "        count_tot += emission_dict[tag][word]\n",
    "        \n",
    "    for word in vocab_list:\n",
    "        count = 0\n",
    "        if word in emission_dict[tag]:\n",
    "            count = emission_dict[tag][word]\n",
    "            \n",
    "        emission_dict[tag][word] = (count + pseudocount) / (count_tot + pseudocount * len(vocabs.keys())) #smoothing\n",
    "\n",
    "for tag in tags:\n",
    "    count_tot = 0\n",
    "    for ftag in tags:  #following tags\n",
    "        if tag in transition_dict and ftag in transition_dict[tag]:\n",
    "            count_tot += transition_dict[tag][ftag]\n",
    "    \n",
    "    for ftag in tags:\n",
    "        count = 0\n",
    "        if tag in transition_dict:\n",
    "            if ftag in transition_dict[tag]:\n",
    "                count = transition_dict[tag][ftag]\n",
    "            transition_dict[tag][ftag] = (count + pseudocount) / (count_tot + pseudocount * len(tags)) #smoothing\n",
    "        else:\n",
    "            transition_dict[tag] = {ftag : (count + pseudocount) / (count_tot + pseudocount * len(tags))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get observation data(test data)##\n",
    "###################################\n",
    "\n",
    "test_file = open(\"WSJ_23.words\")\n",
    "#test_file = open(\"WSJ_24.words\")\n",
    "test_list = test_file.readlines()\n",
    "\n",
    "observ = [] #list of words in the test set(sequence of observation)\n",
    "\n",
    "observ.append(\"SOS\")\n",
    "for i in range(len(test_list)):\n",
    "    if test_list[i] == '\\n':\n",
    "        continue\n",
    "    \n",
    "    test_list[i] = test_list[i].rstrip()\n",
    "    \n",
    "    if test_list[i] not in vocab_set:\n",
    "        observ.append(tag_unknowns(test_list[i])) #handling unknown\n",
    "    else:\n",
    "        observ.append(test_list[i])\n",
    "observ.append(\"EOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##simple 2D transducer##\n",
    "########################\n",
    "#cells represent the likelihood that a particular word is at a particular state\n",
    "#emission table for observed words\n",
    "emiss_table = []\n",
    "for tag in tags:\n",
    "    cols = []\n",
    "    for word in observ:\n",
    "        cols.append(emission_dict[tag][word])\n",
    "    emiss_table.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Executing the Viterbi Algorithm ##\n",
    "#####################################\n",
    "import math \n",
    "max_probs = [[0] * len(observ) for i in range(len(tags))]\n",
    "max_tags = [[None] * len(observ) for i in range(len(tags))]\n",
    "\n",
    "max_score = 0\n",
    "max_i = None\n",
    "\n",
    "#intitialize the starting word of sentence\n",
    "for row in range(len(tags)):\n",
    "    s = tags[row]\n",
    "    if s in transition_dict[\"Begin_Sent\"]:\n",
    "        score = math.log(emiss_table[row][0]) + math.log(transition_dict[\"Begin_Sent\"][s])\n",
    "    else:\n",
    "        score = 0\n",
    "    max_probs[row][0] = score\n",
    "    max_tags[row][0] = 0\n",
    "\n",
    "for col in range(1, len(observ)):    \n",
    "    for t in range(len(tags)):  \n",
    "        max_score = float(\"-inf\")\n",
    "        max_i = None\n",
    "        for pt in range(len(tags)):\n",
    "            \n",
    "            score = max_probs[pt][col-1] + math.log(transition_dict[tags[pt]][tags[t]]) + math.log(emiss_table[t][col])\n",
    "                \n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_i = pt\n",
    "                \n",
    "        max_probs[t][col] = max_score\n",
    "        max_tags[t][col] = max_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Choose the highest POS tags##\n",
    "###############################\n",
    "best_idx = [None] * len(observ)\n",
    "predicted_tags = [None] * len(observ)\n",
    "    \n",
    "argmax = max_probs[0][len(observ) - 2]\n",
    "best_idx[len(observ) - 2] = 0\n",
    "for t in range(1, len(tags)):\n",
    "    if max_probs[t][len(observ) - 2] > argmax:\n",
    "        argmax = max_probs[t][len(observ) - 2]\n",
    "        best_idx[len(observ) - 2] = t\n",
    "\n",
    "predicted_tags[len(observ) - 2] = tags[best_idx[len(observ) - 2]]\n",
    "\n",
    "for i in range(len(observ) - 2, 1, -1):\n",
    "    best_idx[i - 1] = max_tags[best_idx[i]][i]\n",
    "    predicted_tags[i - 1] = tags[best_idx[i - 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "##write tagged file##\n",
    "#####################\n",
    "\n",
    "predicted_tags = predicted_tags[1:len(predicted_tags)-1] #except sos and eos\n",
    "pred_idx = 0\n",
    "\n",
    "#add predicted tags for each line    \n",
    "for i in range(len(test_list)):\n",
    "    test_list[i] = test_list[i].rstrip()\n",
    "    \n",
    "    if test_list[i] == '':\n",
    "        continue\n",
    "    if pred_idx < len(predicted_tags):\n",
    "        test_list[i] = test_list[i] + \"\\t\" + predicted_tags[pred_idx]\n",
    "        pred_idx += 1\n",
    "        \n",
    "test_list[len(test_list)-1] = \"\\n\"\n",
    "\n",
    "output = open(r\"submission.pos\", \"w\")\n",
    "output.write('\\n'.join(test_list))\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
